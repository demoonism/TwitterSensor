{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-------------------------+\n",
      "|id |words          |features                 |\n",
      "+---+---------------+-------------------------+\n",
      "|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|0  |[a, f, c]      |(3,[0,1],[1.0,1.0])      |\n",
      "|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,1.0,2.0])|\n",
      "+---+---------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# Input data: Each row is a bag of words with a ID.\n",
    "df = spark.createDataFrame([\n",
    "    (0, \"a b c\".split(\" \")),\n",
    "    (0, \"a f c\".split(\" \")),\n",
    "    (1, \"a b b c a\".split(\" \"))\n",
    "], [\"id\", \"words\"])\n",
    "\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=3, minDF=2.0)\n",
    "\n",
    "model = cv.fit(df)\n",
    "\n",
    "result = model.transform(df)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a', u'c', u'b']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-----+-------------------------+\n",
      "|id |words2               |label|features2                |\n",
      "+---+---------------------+-----+-------------------------+\n",
      "|0  |[hash1, hash2, hash3]|1.0  |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|0  |[hash1, hash2, hash3]|0.0  |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|1  |[hash4, hash2, hash4]|0.0  |(3,[0],[1.0])            |\n",
      "+---+---------------------+-----+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input data: Each row is a bag of words with a ID.\n",
    "df2 = spark.createDataFrame([\n",
    "    (0, \"hash1 hash2 hash3\".split(\" \"), 1.0),\n",
    "    (0, \"hash1 hash2 hash3\".split(\" \"), 0.0),\n",
    "    (1, \"hash4 hash2 hash4\".split(\" \"), 0.0)\n",
    "], [\"id\", \"words2\", \"label\"])\n",
    "\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "cv = CountVectorizer(inputCol=\"words2\", outputCol=\"features2\", vocabSize=3, minDF=2.0)\n",
    "\n",
    "model2 = cv.fit(df2)\n",
    "\n",
    "result2 = model2.transform(df2)\n",
    "result2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'hash2', u'hash1', u'hash3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = result.join(result2, \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+-------------------------+---------------------+-----+-------------------------+\n",
      "|id |words          |features                 |words2               |label|features2                |\n",
      "+---+---------------+-------------------------+---------------------+-----+-------------------------+\n",
      "|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|[hash1, hash2, hash3]|1.0  |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|[hash1, hash2, hash3]|0.0  |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|0  |[a, f, c]      |(3,[0,1],[1.0,1.0])      |[hash1, hash2, hash3]|1.0  |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|0  |[a, f, c]      |(3,[0,1],[1.0,1.0])      |[hash1, hash2, hash3]|0.0  |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,1.0,2.0])|[hash4, hash2, hash4]|0.0  |(3,[0],[1.0])            |\n",
      "+---+---------------+-------------------------+---------------------+-----+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------+-------------------------+\n",
      "|combine                  |features                 |features2                |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0]|(3,[0,1,2],[1.0,1.0,1.0])|(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|[1.0,1.0,1.0,1.0,1.0,1.0]|(3,[0,1,2],[1.0,1.0,1.0])|(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|[1.0,1.0,0.0,1.0,1.0,1.0]|(3,[0,1],[1.0,1.0])      |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|[1.0,1.0,0.0,1.0,1.0,1.0]|(3,[0,1],[1.0,1.0])      |(3,[0,1,2],[1.0,1.0,1.0])|\n",
      "|[2.0,1.0,2.0,1.0,0.0,0.0]|(3,[0,1,2],[2.0,1.0,2.0])|(3,[0],[1.0])            |\n",
      "+-------------------------+-------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"features\", \"features2\"],\n",
    "    outputCol=\"combine\")\n",
    "\n",
    "output = assembler.transform(c)\n",
    "output.select(\"combine\",\"features\",\"features2\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'a', u'c', u'b', u'hash2', u'hash1', u'hash3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary+ model2.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+\n",
      "|selectedFeatures|combine                  |\n",
      "+----------------+-------------------------+\n",
      "|[1.0,1.0,1.0]   |[1.0,1.0,1.0,1.0,1.0,1.0]|\n",
      "|[1.0,1.0,1.0]   |[1.0,1.0,1.0,1.0,1.0,1.0]|\n",
      "|[1.0,0.0,1.0]   |[1.0,1.0,0.0,1.0,1.0,1.0]|\n",
      "|[1.0,0.0,1.0]   |[1.0,1.0,0.0,1.0,1.0,1.0]|\n",
      "|[2.0,2.0,0.0]   |[2.0,1.0,2.0,1.0,0.0,0.0]|\n",
      "+----------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "selector = ChiSqSelector(numTopFeatures=3, featuresCol=\"combine\",\n",
    "                         outputCol=\"selectedFeatures\", labelCol=\"label\")\n",
    "\n",
    "#smodel = selector.fit(output)\n",
    "#smodel.transform(output).selectedFeatures\n",
    "result = selector.fit(output).transform(output)\n",
    "result.select(\"selectedFeatures\", \"combine\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smodel.selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
